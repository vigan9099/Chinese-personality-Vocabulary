{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "import time\n",
    "data = pd.read_excel('人格.xlsx') # 1520个词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取excel表格里的词\n",
    "words = []\n",
    "for word in data['word']:\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tic= time.time()\n",
    "# wvmodel_Tencent = gensim.models.KeyedVectors.load_word2vec_format('E:\\词向量\\Tencent_AILab_ChineseEmbedding\\Tencent_AILab_ChineseEmbedding.txt', binary=False, encoding='utf-8')\n",
    "# toc = time.time()\n",
    "# print('腾讯词向量读取完毕，共耗时',toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "维基词向量读取完毕，共耗时 84.77603888511658\n"
     ]
    }
   ],
   "source": [
    "tic= time.time()\n",
    "wvmodel_wiki = gensim.models.KeyedVectors.load_word2vec_format('E:\\pyproject/网络暴力语义模型/embedding/sgns.wiki.bigram-char/sgns.wiki.bigram-char', binary=False, encoding='utf-8')\n",
    "toc = time.time()\n",
    "print('维基词向量读取完毕，共耗时',toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic= time.time()\n",
    "# vmodel_weibo = gensim.models.KeyedVectors.load_word2vec_format('E:\\pyproject/网络暴力语义模型/embedding/sgns.weibo.bigram-char', binary=False, encoding='utf-8')\n",
    "# toc = time.time()\n",
    "# print('微博词向量读取完毕，共耗时',toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic= time.time()\n",
    "# wvmodel_zhihu = gensim.models.KeyedVectors.load_word2vec_format('E:\\pyproject/网络暴力语义模型/embedding/sgns.zhihu.bigram-char', binary=False, encoding='utf-8')\n",
    "# toc = time.time()\n",
    "# print('知乎词向量读取完毕，共耗时',toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tic= time.time()\n",
    "# wvmodel_renmin = gensim.models.KeyedVectors.load_word2vec_format('E:\\pyproject/网络暴力语义模型/embedding/sgns.renmin.bigram-char', binary=False, encoding='utf-8')\n",
    "# toc = time.time()\n",
    "# print('人民词向量读取完毕，共耗时',toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model_list = [wvmodel_wiki,vmodel_weibo,wvmodel_zhihu,wvmodel_Tencent,wvmodel_renmin]\n",
    "model_list = [wvmodel_wiki]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['维基']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def similar(word,n,vmodel):\n",
    "    global count\n",
    "    try:\n",
    "        # print(model_name[k],'词向量的近义词有：')\n",
    "#             print(vmodel.similar_by_word(word,n) )\n",
    "        for i in vmodel.similar_by_word(word,n): #返回元组\n",
    "            sim_word.append(i[0])\n",
    "            sim_score.append(i[1])\n",
    "        sim_word.append(word)\n",
    "        sim_score.append(1)\n",
    "    except:\n",
    "        count+=1\n",
    "        # print('  ',model_name[k],'没有'+word+'词向量！')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec(words_list,wvmodel):\n",
    "    my_vector_dict = {}\n",
    "    for word in words_list:\n",
    "        word = str(word)\n",
    "        try:\n",
    "            my_vector_dict[word] = wvmodel.get_vector(word) # 读取所有词向量，其中有可能出现重复的词\n",
    "        except:\n",
    "            print(word,'没有找到对应的向量或出现了重复词')\n",
    "            continue\n",
    "    name_list = []\n",
    "    vec_list = []\n",
    "    for k in my_vector_dict:\n",
    "        name_list.append(k)\n",
    "        vec_list.append(my_vector_dict[k])\n",
    "    return name_list,vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "维基 词向量的近义词有：\n",
      "[('重情义', 0.7765159606933594), ('重情', 0.7487812042236328), ('有情人', 0.7419861555099487), ('无情无义', 0.7264854907989502), ('才情', 0.7224937677383423)]\n"
     ]
    }
   ],
   "source": [
    "similar('有情有义',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把每一个人格词都找10个近义词词向量，不同的词向量读取的词保存到不同的excel里\n",
    "\n",
    "腾讯词向量人格词.xlsx\n",
    "维基词向量人格词.xlsx\n",
    "......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_word.index('坚强')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_score[583]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "维基\n",
      "维基 991 个词没有收录\n",
      "维基\n"
     ]
    }
   ],
   "source": [
    "for N in range(3,6): # 找几个词\n",
    "    for k,model in enumerate(model_list):\n",
    "        print(model_name[k])\n",
    "        sim_word = []\n",
    "        sim_score= []\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            similar(word,N,model)\n",
    "        # sim_word 代表所有被当前词向量收录的词\n",
    "        print(model_name[k],count,'个词没有收录')\n",
    "        name_list,vec_list = get_vec(sim_word,model)\n",
    "        save_similar = []\n",
    "        for i,j in enumerate(name_list):\n",
    "             save_similar.append(sim_score[sim_word.index(j)])\n",
    "        toexcel = pd.DataFrame(vec_list)\n",
    "        toexcel['人格词'] = name_list\n",
    "        toexcel['相似度'] = save_similar\n",
    "        toexcel.to_excel('找'+str(N)+'【'+model_name[k] + '】共'+str(len(name_list))+'人格词.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
